{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K \n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense \n",
    "from keras import optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_width, img_height = 128, 128\n",
    "TrainData = pd.read_csv('TrainAnnotations.csv')\n",
    "\n",
    "Annotations = TrainData['annotation'].tolist()\n",
    "#display(Image(FileNames[0]))\n",
    "#TrainData.shape[0]\n",
    "\n",
    "Annotations_one_hot = to_categorical(Annotations)\n",
    "\n",
    "print(Annotations_one_hot)\n",
    "\n",
    "\n",
    "FileNames = ['TrainData\\\\'+ fname for fname in TrainData['file_name'].tolist()]\n",
    "Train_image = []\n",
    "\n",
    "for i in range(TrainData.shape[0]):\n",
    "    #img = resize(FileNames[i],(32,32,3))\n",
    "    img = keras.preprocessing.image.load_img(FileNames[i],target_size = (128,128))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    Train_image.append(img)\n",
    "\n",
    "X = np.array(Train_image)\n",
    "\n",
    "# Check if the images are RGB and change the channels likewise\n",
    "if K.image_data_format() == 'channels_first':\n",
    "  input_shape= (3, img_width, img_height)\n",
    "else:\n",
    "  input_shape = (img_width, img_height, 3)\n",
    "\n",
    "Y = np.array(Annotations)\n",
    "\n",
    "\n",
    "\n",
    "# create iterator\n",
    "#it = datagen.flow(X, Y)\n",
    "\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size = 0.2, random_state = 10 )\n",
    "Y_train = np_utils.to_categorical(Y_train, 5)\n",
    "Y_val = np_utils.to_categorical(Y_val, 5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model(learning_rate = 0.0001):\n",
    "  \n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32,(3,3), input_shape = input_shape)) #32 #(3,3)\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "  model.add(Conv2D(64,(3,3))) #64\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "  model.add(Conv2D(128,(2,2))) #128\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  model.add(Dense(128))#64\n",
    "  model.add(Activation('relu'))#relu\n",
    "  model.add(Dropout(0.5))#0.5\n",
    "  model.add(Dense(64))#64\n",
    "  model.add(Activation('relu'))#relu\n",
    "  model.add(Dropout(0.5))#0.5\n",
    "  model.add(Dense(5))\n",
    "  model.add(Activation('softmax'))\n",
    "\n",
    "  optimizer = optimizers.adam(learning_rate)\n",
    "                                              \n",
    "  model.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics = ['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size : 16 Learning rate: 0.001\n",
      "Train on 1020 samples, validate on 255 samples\n",
      "Epoch 1/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 1.5542 - accuracy: 0.3363 - val_loss: 1.5333 - val_accuracy: 0.3412\n",
      "Epoch 2/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 1.4356 - accuracy: 0.3882 - val_loss: 1.3759 - val_accuracy: 0.4980\n",
      "Epoch 3/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 1.3327 - accuracy: 0.4804 - val_loss: 1.1849 - val_accuracy: 0.5216\n",
      "Epoch 4/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 1.2093 - accuracy: 0.5206 - val_loss: 1.0657 - val_accuracy: 0.6039\n",
      "Epoch 5/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 1.0540 - accuracy: 0.5814 - val_loss: 1.0029 - val_accuracy: 0.5922\n",
      "Epoch 6/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.9087 - accuracy: 0.6255 - val_loss: 0.8860 - val_accuracy: 0.5765\n",
      "Epoch 7/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.8735 - accuracy: 0.6294 - val_loss: 0.8570 - val_accuracy: 0.6078\n",
      "Epoch 8/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.7912 - accuracy: 0.6902 - val_loss: 0.8301 - val_accuracy: 0.6431\n",
      "Epoch 9/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.7143 - accuracy: 0.7098 - val_loss: 0.7378 - val_accuracy: 0.7059\n",
      "Epoch 10/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.6360 - accuracy: 0.7363 - val_loss: 0.7343 - val_accuracy: 0.7137\n",
      "Epoch 11/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.7248 - accuracy: 0.7284 - val_loss: 0.6583 - val_accuracy: 0.7176\n",
      "Epoch 12/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.5015 - accuracy: 0.7922 - val_loss: 0.6325 - val_accuracy: 0.7686\n",
      "Epoch 13/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.4424 - accuracy: 0.8186 - val_loss: 0.6173 - val_accuracy: 0.7961\n",
      "Epoch 14/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.4577 - accuracy: 0.8353 - val_loss: 0.5712 - val_accuracy: 0.8039\n",
      "Epoch 15/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.3524 - accuracy: 0.8608 - val_loss: 0.5655 - val_accuracy: 0.7961\n",
      "Epoch 16/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.3366 - accuracy: 0.8686 - val_loss: 0.5240 - val_accuracy: 0.7725\n",
      "Epoch 17/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.4424 - accuracy: 0.8294 - val_loss: 0.6760 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.3045 - accuracy: 0.8804 - val_loss: 0.6164 - val_accuracy: 0.7843\n",
      "Epoch 19/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.2942 - accuracy: 0.9088 - val_loss: 0.6456 - val_accuracy: 0.8118\n",
      "Epoch 20/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.2403 - accuracy: 0.9147 - val_loss: 0.6998 - val_accuracy: 0.7922\n",
      "Epoch 21/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1989 - accuracy: 0.9275 - val_loss: 0.9894 - val_accuracy: 0.7882\n",
      "Epoch 22/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.2331 - accuracy: 0.9098 - val_loss: 0.8531 - val_accuracy: 0.7843\n",
      "Epoch 23/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.2216 - accuracy: 0.9137 - val_loss: 0.6819 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.2220 - accuracy: 0.9294 - val_loss: 0.9363 - val_accuracy: 0.8157\n",
      "Epoch 25/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.2181 - accuracy: 0.9196 - val_loss: 0.8944 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1847 - accuracy: 0.9451 - val_loss: 0.5901 - val_accuracy: 0.8235\n",
      "Epoch 27/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1734 - accuracy: 0.9422 - val_loss: 0.6275 - val_accuracy: 0.8118\n",
      "Epoch 28/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1920 - accuracy: 0.9265 - val_loss: 0.7582 - val_accuracy: 0.7882\n",
      "Epoch 29/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1395 - accuracy: 0.9480 - val_loss: 0.8153 - val_accuracy: 0.8039\n",
      "Epoch 30/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1624 - accuracy: 0.9461 - val_loss: 0.7494 - val_accuracy: 0.8157\n",
      "Epoch 31/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.1460 - accuracy: 0.9510 - val_loss: 0.8061 - val_accuracy: 0.8039\n",
      "Epoch 32/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1435 - accuracy: 0.9500 - val_loss: 0.6695 - val_accuracy: 0.8039\n",
      "Epoch 33/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1679 - accuracy: 0.9363 - val_loss: 0.7840 - val_accuracy: 0.8235\n",
      "Epoch 34/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1286 - accuracy: 0.9578 - val_loss: 0.8640 - val_accuracy: 0.8078\n",
      "Epoch 35/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1595 - accuracy: 0.9441 - val_loss: 0.8850 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1640 - accuracy: 0.9441 - val_loss: 0.6741 - val_accuracy: 0.8039\n",
      "Epoch 37/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1414 - accuracy: 0.9510 - val_loss: 0.6162 - val_accuracy: 0.8196\n",
      "Epoch 38/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0960 - accuracy: 0.9676 - val_loss: 0.9824 - val_accuracy: 0.8196\n",
      "Epoch 39/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1343 - accuracy: 0.9608 - val_loss: 0.8831 - val_accuracy: 0.7961\n",
      "Epoch 40/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0891 - accuracy: 0.9676 - val_loss: 1.2241 - val_accuracy: 0.7922\n",
      "Epoch 41/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1031 - accuracy: 0.9676 - val_loss: 0.9146 - val_accuracy: 0.8235\n",
      "Epoch 42/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0731 - accuracy: 0.9804 - val_loss: 1.1597 - val_accuracy: 0.7961\n",
      "Epoch 43/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1146 - accuracy: 0.9549 - val_loss: 1.0410 - val_accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1001 - accuracy: 0.9696 - val_loss: 1.0304 - val_accuracy: 0.8078\n",
      "Epoch 45/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1094 - accuracy: 0.9588 - val_loss: 0.9261 - val_accuracy: 0.8039\n",
      "Epoch 46/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1003 - accuracy: 0.9608 - val_loss: 1.1874 - val_accuracy: 0.8196\n",
      "Epoch 47/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1591 - accuracy: 0.9510 - val_loss: 0.9948 - val_accuracy: 0.8078\n",
      "Epoch 48/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.1380 - accuracy: 0.9510 - val_loss: 1.1916 - val_accuracy: 0.8157\n",
      "Epoch 49/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1236 - accuracy: 0.9637 - val_loss: 1.0140 - val_accuracy: 0.8078\n",
      "Epoch 50/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0843 - accuracy: 0.9716 - val_loss: 1.1721 - val_accuracy: 0.8196\n",
      "Epoch 51/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0913 - accuracy: 0.9716 - val_loss: 1.0057 - val_accuracy: 0.8235\n",
      "Epoch 52/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0804 - accuracy: 0.9706 - val_loss: 1.2406 - val_accuracy: 0.8078\n",
      "Epoch 53/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.1053 - accuracy: 0.9608 - val_loss: 0.9395 - val_accuracy: 0.8078\n",
      "Epoch 54/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.1283 - accuracy: 0.9578 - val_loss: 1.0527 - val_accuracy: 0.8235\n",
      "Epoch 55/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0945 - accuracy: 0.9627 - val_loss: 1.0069 - val_accuracy: 0.8275\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0783 - accuracy: 0.9735 - val_loss: 1.4824 - val_accuracy: 0.8235\n",
      "Epoch 57/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0907 - accuracy: 0.9627 - val_loss: 1.0030 - val_accuracy: 0.8392\n",
      "Epoch 58/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0801 - accuracy: 0.9755 - val_loss: 1.0286 - val_accuracy: 0.8353\n",
      "Epoch 59/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0760 - accuracy: 0.9696 - val_loss: 1.2666 - val_accuracy: 0.8275\n",
      "Epoch 60/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0651 - accuracy: 0.9725 - val_loss: 1.3630 - val_accuracy: 0.8078\n",
      "Epoch 61/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.1020 - accuracy: 0.9559 - val_loss: 1.3334 - val_accuracy: 0.8157\n",
      "Epoch 62/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0837 - accuracy: 0.9716 - val_loss: 1.4176 - val_accuracy: 0.8314\n",
      "Epoch 63/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0821 - accuracy: 0.9637 - val_loss: 1.1441 - val_accuracy: 0.8078\n",
      "Epoch 64/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0853 - accuracy: 0.9627 - val_loss: 1.2458 - val_accuracy: 0.8039\n",
      "Epoch 65/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1123 - accuracy: 0.9539 - val_loss: 1.1088 - val_accuracy: 0.8000\n",
      "Epoch 66/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1166 - accuracy: 0.9637 - val_loss: 1.5301 - val_accuracy: 0.8118\n",
      "Epoch 67/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0632 - accuracy: 0.9716 - val_loss: 1.8116 - val_accuracy: 0.8118\n",
      "Epoch 68/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0643 - accuracy: 0.9716 - val_loss: 1.7975 - val_accuracy: 0.8196\n",
      "Epoch 69/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1194 - accuracy: 0.9569 - val_loss: 1.0972 - val_accuracy: 0.8314\n",
      "Epoch 70/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.1024 - accuracy: 0.9667 - val_loss: 1.1385 - val_accuracy: 0.8196\n",
      "Epoch 71/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0896 - accuracy: 0.9696 - val_loss: 0.9285 - val_accuracy: 0.8118\n",
      "Epoch 72/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0868 - accuracy: 0.9657 - val_loss: 1.0947 - val_accuracy: 0.8118\n",
      "Epoch 73/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.1060 - accuracy: 0.9559 - val_loss: 1.2584 - val_accuracy: 0.8235\n",
      "Epoch 74/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0732 - accuracy: 0.9765 - val_loss: 1.1246 - val_accuracy: 0.8157\n",
      "Epoch 75/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0756 - accuracy: 0.9735 - val_loss: 1.2819 - val_accuracy: 0.8275\n",
      "Epoch 76/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0740 - accuracy: 0.9706 - val_loss: 1.2539 - val_accuracy: 0.8157\n",
      "Epoch 77/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0828 - accuracy: 0.9735 - val_loss: 1.3772 - val_accuracy: 0.8353\n",
      "Epoch 78/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0850 - accuracy: 0.9706 - val_loss: 1.6561 - val_accuracy: 0.8118\n",
      "Epoch 79/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0651 - accuracy: 0.9696 - val_loss: 1.6518 - val_accuracy: 0.8078\n",
      "Epoch 80/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0541 - accuracy: 0.9725 - val_loss: 1.2944 - val_accuracy: 0.8275\n",
      "Epoch 81/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0680 - accuracy: 0.9775 - val_loss: 1.2492 - val_accuracy: 0.8196\n",
      "Epoch 82/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0536 - accuracy: 0.9814 - val_loss: 1.5394 - val_accuracy: 0.8196\n",
      "Epoch 83/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0581 - accuracy: 0.9784 - val_loss: 0.9556 - val_accuracy: 0.8118\n",
      "Epoch 84/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0643 - accuracy: 0.9794 - val_loss: 1.1173 - val_accuracy: 0.8000\n",
      "Epoch 85/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0693 - accuracy: 0.9745 - val_loss: 1.4610 - val_accuracy: 0.8275\n",
      "Epoch 86/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0831 - accuracy: 0.9647 - val_loss: 1.4696 - val_accuracy: 0.8078\n",
      "Epoch 87/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0551 - accuracy: 0.9755 - val_loss: 1.9886 - val_accuracy: 0.8196\n",
      "Epoch 88/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0722 - accuracy: 0.9696 - val_loss: 1.4024 - val_accuracy: 0.8235\n",
      "Epoch 89/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0653 - accuracy: 0.9804 - val_loss: 1.6273 - val_accuracy: 0.8353\n",
      "Epoch 90/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0510 - accuracy: 0.9853 - val_loss: 1.2961 - val_accuracy: 0.8471\n",
      "Epoch 91/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0453 - accuracy: 0.9853 - val_loss: 1.8668 - val_accuracy: 0.8275\n",
      "Epoch 92/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0621 - accuracy: 0.9794 - val_loss: 1.3184 - val_accuracy: 0.8078\n",
      "Epoch 93/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0580 - accuracy: 0.9765 - val_loss: 2.0170 - val_accuracy: 0.8196\n",
      "Epoch 94/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0595 - accuracy: 0.9784 - val_loss: 1.8823 - val_accuracy: 0.8275\n",
      "Epoch 95/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0614 - accuracy: 0.9745 - val_loss: 1.5443 - val_accuracy: 0.8314\n",
      "Epoch 96/100\n",
      "1020/1020 [==============================] - 5s 4ms/step - loss: 0.0600 - accuracy: 0.9735 - val_loss: 1.8104 - val_accuracy: 0.8353\n",
      "Epoch 97/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0637 - accuracy: 0.9775 - val_loss: 1.7703 - val_accuracy: 0.8157\n",
      "Epoch 98/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0368 - accuracy: 0.9873 - val_loss: 2.2878 - val_accuracy: 0.8275\n",
      "Epoch 99/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0933 - accuracy: 0.9676 - val_loss: 1.2628 - val_accuracy: 0.8157\n",
      "Epoch 100/100\n",
      "1020/1020 [==============================] - 5s 5ms/step - loss: 0.0579 - accuracy: 0.9765 - val_loss: 1.5873 - val_accuracy: 0.8471\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [16]\n",
    "\n",
    "learning_rates = [0.001]\n",
    "\n",
    "\n",
    "histories = []\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "i = 0\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "  \n",
    "  for learning_rate in learning_rates:\n",
    "    \n",
    "    print(\"Batch Size : {} Learning rate: {}\".format(batch_size, learning_rate))\n",
    "    \n",
    "    #train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "   # train_generator = train_datagen.flow_from_directory('TrainData\\\\', target_size =(img_width, img_height),class_mode = 'categorical')\n",
    "\n",
    "    #validation_generator = train_datagen.flow_from_directory( val_data_dir, target_size =(img_width, img_height), batch_size = batch_size, class_mode ='categorical') \n",
    " # history = model.fit_generator(train_generator, steps_per_epoch = num_train // batch_size, epochs = epochs, validation_data = validation_generator, validation_steps = num_val// batch_size)\n",
    "    \n",
    "    model = get_model(learning_rate)\n",
    "\n",
    "  \n",
    "\n",
    "    Train_fit = model.fit(X_train,Y_train,batch_size = 16, epochs = 100, validation_data= (X_val, Y_val))#16#50\n",
    "    \n",
    "    \n",
    "    # fits the model on batches with real-time data augmentation:\n",
    "    #Train_fit = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),epochs=50,validation_data= (X_val, Y_val))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #model.save_weights(\"model_new\"+ str(i+1) +\".h5\")\n",
    "    \n",
    "    model.save(\"model_new\"+ str(i+1) +\".h5\")\n",
    "    \n",
    "    histories.append(model.history.history)\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntest_set_dir = \"/content/drive/My Drive/NN-ProjectC/Project_C1/Test/\"\\n\\nnum_test = len(os.listdir(test_set_dir))\\n\\nprint (\"Number of images in test set: \", num_test)\\n\\nmodel = get_model(0.0001)\\n\\nmodel.load_weights(\"/content/model_new1.h5\")\\n  \\ntest_datagen = ImageDataGenerator(rescale=1./255)\\n\\ntest_generator = test_datagen.flow_from_directory(test_set_dir, target_size =(img_width, img_height), \\n                                                  batch_size = batch_size, class_mode =None, shuffle = False) \\n\\ntest_steps_per_epoch = numpy.math.ceil(test_generator.samples / test_generator.batch_size)\\n\\npredictions = model.predict_generator(test_generator, steps = test_steps_per_epoch)\\n\\nprint(\"PREDICTIONS: --->\")\\nprint(predictions)\\n\\npredicted_classes = numpy.argmax(predictions, axis=1)\\n\\nprint(\"PREDICTED CLASSES: --->\")\\nprint (predicted_classes)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import sklearn.metrics as metrics\n",
    "import glob\n",
    "img_width, img_height = 128, 128\n",
    "batch_size = 8\n",
    "epochs = 100\n",
    "Testpath = \"TestData/*.jpg\"\n",
    "Testfiles = glob.glob(Testpath)\n",
    "Test_image = []\n",
    "for i in range (len(Testfiles)):\n",
    "    img = keras.preprocessing.image.load_img(Testfiles[i],target_size = (128, 128))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    Test_image.append(img)\n",
    "   \n",
    "   \n",
    "X_test = np.array(Test_image)\n",
    "YPredict_test = model.predict(X_test)\n",
    "Predict_test = np.argmax(YPredict_test, axis=1)\n",
    "Predict_one_hot = to_categorical(Predict_test)\n",
    "\n",
    "print(Predict_one_hot)\n",
    "set(Predict_test)\n",
    "result = pd.DataFrame(Predict_one_hot)\n",
    "result.to_csv(\"predict.csv\",header=False, index=False)\n",
    "'''\n",
    "test_set_dir = \"/content/drive/My Drive/NN-ProjectC/Project_C1/Test/\"\n",
    "\n",
    "num_test = len(os.listdir(test_set_dir))\n",
    "\n",
    "print (\"Number of images in test set: \", num_test)\n",
    "\n",
    "model = get_model(0.0001)\n",
    "\n",
    "model.load_weights(\"/content/model_new1.h5\")\n",
    "  \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_set_dir, target_size =(img_width, img_height), \n",
    "                                                  batch_size = batch_size, class_mode =None, shuffle = False) \n",
    "\n",
    "test_steps_per_epoch = numpy.math.ceil(test_generator.samples / test_generator.batch_size)\n",
    "\n",
    "predictions = model.predict_generator(test_generator, steps = test_steps_per_epoch)\n",
    "\n",
    "print(\"PREDICTIONS: --->\")\n",
    "print(predictions)\n",
    "\n",
    "predicted_classes = numpy.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"PREDICTED CLASSES: --->\")\n",
    "print (predicted_classes)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
